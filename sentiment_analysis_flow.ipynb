{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>reviewer_rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>place_of_review</th>\n",
       "      <th>date_of_review</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>product_name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>badminton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>badminton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewer_name  reviewer_rating            review_title  \\\n",
       "0       Kamal Suresh              4.0            Nice product   \n",
       "1  Flipkart Customer              1.0  Don't waste your money   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  Nice product, good quality, but price is now r...   \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...   \n",
       "\n",
       "              place_of_review date_of_review  up_votes  down_votes  \\\n",
       "0  Certified Buyer, Chirakkal       Feb 2021     889.0        64.0   \n",
       "1  Certified Buyer, Hyderabad       Feb 2021     109.0         6.0   \n",
       "\n",
       "  product_name  sentiment  \n",
       "0    badminton          1  \n",
       "1    badminton          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('product_reviews.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Data\n",
    "X = df['review_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8604,) (2151,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 11:47:24 INFO mlflow.tracking.fluent: Experiment with name 'sentiment_prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/USER/Documents/Data%20Science%20and%20Analytics/InnomaticsResearchLabs/sentiment_analysis/mlruns/301106958472313625', creation_time=1711622844923, experiment_id='301106958472313625', last_update_time=1711622844923, lifecycle_stage='active', name='sentiment_prediction', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"sentiment_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_text):\n",
    "    \n",
    "    # Removing special characters and digits\n",
    "\n",
    "    sentence = re.sub(\"[^a-zA-Z]|READ MORE\", \" \", raw_text)\n",
    "    \n",
    "    # change sentence to lower case\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_tokens = [word for word in lemmatized_tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join and return\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice product good quality price rising bad sign wa affordable price especially play everyday kindly help u term price thank'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of processed word\n",
    "preprocess(df['review_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Text to Numerical vectors - BOW Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "(8604, 2554)\n"
     ]
    }
   ],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate a vectorizer\n",
    "vect = CountVectorizer(preprocessor=preprocess)\n",
    "%time\n",
    "X_train_bow = vect.fit_transform(X_train)\n",
    "print(X_train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "(2151, 2554)\n"
     ]
    }
   ],
   "source": [
    "# transform testing data (using training data's features)\n",
    "%time\n",
    "X_test_bow = vect.transform(X_test)\n",
    "print(X_test_bow.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Auto Logging Naive Bayes Demo Experiment Run using MLFlow**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 11:47:36 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# import classifier from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB() # instantiate a Multinomial Naive Bayes model\n",
    "\n",
    "mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    %time\n",
    "    nb.fit(X_train_bow, y_train) # train the model(timing it with an IPython \"magic command\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create an optimal workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 11:47:47 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline with caching\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]\n",
    ")\n",
    "\n",
    "MAX_FEATURES = [1000, 1500, 2000]\n",
    "ALPHA = [1, 10]\n",
    "\n",
    "# Observe the Key Value Pair format\n",
    "parameter_grid = [\n",
    "    {\n",
    "        'vectorization__preprocessor': [preprocess],\n",
    "        'vectorization__max_features': MAX_FEATURES,\n",
    "        'nb__alpha': ALPHA\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=parameter_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Initialize the auto logger\n",
    "# max_tuning_runs=None will make sure that all the runs are recorded.\n",
    "# By default top 5 runs will be recorded for each experiment\n",
    "mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    %time\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# Improving the efficiency by applying cleaning the text data before hand\n",
    "\n",
    "%time\n",
    "X_train_clean = X_train.apply(lambda raw_txt: preprocess(raw_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "X_test_clean = X_test.apply(lambda raw_txt: preprocess(raw_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Auto Logging All Experiment Runs using MLFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 11:53:21 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Train Score:  0.9341006445684634\n",
      "Score on Test Data:  0.9265457926545793\n",
      "********** logistic_regression **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 11:53:45 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Train Score:  0.9120177560369175\n",
      "Score on Test Data:  0.905625290562529\n",
      "********** random_forest **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/28 12:06:26 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Train Score:  0.908531005499777\n",
      "Score on Test Data:  0.9065550906555091\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ]),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'random_forest': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__alpha' : [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga'],\n",
    "            'classifier__class_weight': ['balanced'],\n",
    "        }\n",
    "    ],\n",
    "    'random_forest': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000],\n",
    "            'classifier__max_depth': [None, 5, 10],\n",
    "            'classifier__n_estimators': [10,20,25],\n",
    "            'classifier__min_samples_leaf': [2],\n",
    "            'classifier__bootstrap': [True,False],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each algorithm\n",
    "best_models = {}\n",
    "\n",
    "for algorithm in pipelines.keys():\n",
    "    print(\"*\"*10, algorithm, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algorithm], \n",
    "                               param_grid=param_grids[algorithm], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time\n",
    "        grid_search.fit(X_train_clean, y_train)\n",
    "    \n",
    "    best_models[algorithm] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Score on Test Data: ', grid_search.score(X_test_clean, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the auto logger\n",
    "\n",
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Custom Experiment Tracking and Database Integration with MLFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///c:/Users/USER/Documents/Data Science and '\n",
       " 'Analytics/InnomaticsResearchLabs/sentiment_analysis/mlruns/1'), creation_time=1711369401488, experiment_id='1', last_update_time=1711369401488, lifecycle_stage='active', name='Sentiment Prediction', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "mlflow.set_experiment(\"Sentiment Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Train Score:  0.9341006445684634\n",
      "Test Score:  0.9265457926545793\n",
      "Fit Time:  4.472436904907227\n",
      "Predict Time:  0.01397705078125\n",
      "Model Size:  78490\n",
      "\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Train Score:  0.9120177560369175\n",
      "Test Score:  0.9060901906090191\n",
      "Fit Time:  759.0083088874817\n",
      "Predict Time:  0.01399087905883789\n",
      "Model Size:  84301\n",
      "\n",
      "********** random_forest **********\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Train Score:  0.906788238314663\n",
      "Test Score:  0.8744769874476988\n",
      "Fit Time:  193.5282428264618\n",
      "Predict Time:  0.029982328414916992\n",
      "Model Size:  938274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev = \"Aminat Owodunni\"\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "\n",
    "    # Fit\n",
    "    start_fit_time = time.time()\n",
    "    grid_search.fit(X_train_clean, y_train)\n",
    "    end_fit_time = time.time()\n",
    "\n",
    "    # Predict\n",
    "    start_predict_time = time.time()\n",
    "    y_pred = grid_search.predict(X_test_clean)\n",
    "    end_predict_time = time.time()\n",
    "\n",
    "    # Saving the best model\n",
    "    joblib.dump(grid_search.best_estimator_, f'best_models/{algo}.pkl')\n",
    "    model_size = os.path.getsize(f'best_models/{algo}.pkl')\n",
    "\n",
    "    # Pring Log\n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test_clean, y_test))\n",
    "    print(\"Fit Time: \", end_fit_time - start_fit_time)\n",
    "    print(\"Predict Time: \", end_predict_time - start_predict_time)\n",
    "    print(\"Model Size: \", model_size)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    # Start the experiment run\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log tags with mlflow.set_tag()\n",
    "        mlflow.set_tag(\"developer\", dev)\n",
    "\n",
    "        # Log Parameters with mlflow.log_param()\n",
    "        mlflow.log_param(\"algorithm\", algo)\n",
    "        mlflow.log_param(\"hyperparameter_grid\", param_grids[algo])\n",
    "        mlflow.log_param(\"best_hyperparameter\", grid_search.best_params_)\n",
    "\n",
    "        # Log Metrics with mlflow.log_metric()\n",
    "        mlflow.log_metric(\"train_score\", grid_search.best_score_)\n",
    "        mlflow.log_metric(\"test_score\", grid_search.score(X_test_clean, y_test))\n",
    "        mlflow.log_metric(\"fit_time\", end_fit_time - start_fit_time)\n",
    "        mlflow.log_metric(\"predict_time\", end_predict_time - start_predict_time)\n",
    "        mlflow.log_metric(\"model_size\", model_size)\n",
    "\n",
    "        # Log Model using mlflow.sklearn.log_model()\n",
    "        mlflow.sklearn.log_model(grid_search.best_estimator_, f\"{algo}_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
